{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install arabert transformers"
      ],
      "metadata": {
        "id": "ZiXLnXsrEHb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "ARj36mtC2CcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2F5PhQHfDxli"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TextClassificationPipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofst1iulEF9N",
        "outputId": "7a7a03cd-9810-4768-c9e1-9c451ee1fd58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('/content/drive/MyDrive/Vaccine/df_safe_train.xlsx')"
      ],
      "metadata": {
        "id": "MInl_yI4y8s4"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj00BoIXzR1h",
        "outputId": "d5498ccb-54b0-4ef3-81b2-75bd13e4c3da"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   ID       179 non-null    float64\n",
            " 1   Arabic   400 non-null    object \n",
            " 2   English  148 non-null    object \n",
            " 3   Label    399 non-null    float64\n",
            " 4   text     400 non-null    object \n",
            "dtypes: float64(2), object(3)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n"
      ],
      "metadata": {
        "id": "fIbO4Uv5zWJ5"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'] = df['Label'].replace(3, 2)"
      ],
      "metadata": {
        "id": "Mh5rGvVeR2RO"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_54_N_TRJ08",
        "outputId": "fc654d6f-7680-44d2-a608-628e5dcd6f27"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    193\n",
              "0    109\n",
              "1     98\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Arabic'], df['Label'], test_size=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "29GDElR2z1CY"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load AraBERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('aubmindlab/bert-base-arabert')\n",
        "model = BertForSequenceClassification.from_pretrained('aubmindlab/bert-base-arabert', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Load mBERT tokenizer and model\n",
        "#tokenizer = BertTokenizer.from_pretrained('asafaya/bert-base-arabic')\n",
        "#model = BertForSequenceClassification.from_pretrained('asafaya/bert-base-arabic', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Load BERT Large tokenizer and model\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=len(df['Label'].unique()))\n",
        "\n",
        "#Load AraElectra\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(label_encoder.classes_))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPlDT_kLz8us",
        "outputId": "c20dfe31-5d51-473d-96d9-ff3eec3a07d4"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True)\n"
      ],
      "metadata": {
        "id": "DA4vnlai0BJz"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "import torch\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "FvsQxuOf0nMM"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import EvalPrediction\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    return {\"accuracy\": (preds == p.label_ids).mean()}\n"
      ],
      "metadata": {
        "id": "nBiV2zPL1xMK"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with accuracy as a metric\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.001,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "T_-kVdam1AuX",
        "outputId": "e12a19e1-1681-40ba-e1b6-77dc9cbe8834"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 03:08, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.222000</td>\n",
              "      <td>1.037555</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.027800</td>\n",
              "      <td>1.038764</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.022200</td>\n",
              "      <td>0.948768</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.719700</td>\n",
              "      <td>1.159126</td>\n",
              "      <td>0.425000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.663400</td>\n",
              "      <td>1.183104</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.175100</td>\n",
              "      <td>1.614715</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>1.910102</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.063100</td>\n",
              "      <td>2.160999</td>\n",
              "      <td>0.487500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>1.792511</td>\n",
              "      <td>0.637500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.033700</td>\n",
              "      <td>2.040210</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=0.48843288006329977, metrics={'train_runtime': 189.2112, 'train_samples_per_second': 16.912, 'train_steps_per_second': 1.427, 'total_flos': 317383409740800.0, 'train_loss': 0.48843288006329977, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "results = trainer.evaluate()\n",
        "print(\"Validation Results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "szDHwekC1-dZ",
        "outputId": "a2a9811b-f819-4d1d-e4c9-0ba03101b88d"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results: {'eval_loss': 0.9487676620483398, 'eval_accuracy': 0.55, 'eval_runtime': 0.6648, 'eval_samples_per_second': 120.338, 'eval_steps_per_second': 10.53, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on validation set\n",
        "val_preds = trainer.predict(val_dataset)\n",
        "val_preds_labels = val_preds.predictions.argmax(-1)\n",
        "accuracy = accuracy_score(val_labels, val_preds_labels)\n",
        "print(\"Validation Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WxrlRwWA3GOn",
        "outputId": "91f32855-0d2d-4cc8-feba-761d7614b4f5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(val_labels, val_preds_labels, average='weighted')\n",
        "recall = recall_score(val_labels, val_preds_labels, average='weighted')\n",
        "f1 = f1_score(val_labels, val_preds_labels, average='weighted')\n",
        "\n",
        "print(\"Validation Precision:\", precision)\n",
        "print(\"Validation Recall:\", recall)\n",
        "print(\"Validation F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dick_f7YmQ_Q",
        "outputId": "e5bf04d7-9cbb-47f6-a36d-fd27e1e9689b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Precision: 0.5543617021276596\n",
            "Validation Recall: 0.525\n",
            "Validation F1-Score: 0.5158211794546608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference-Preidct new label"
      ],
      "metadata": {
        "id": "5LqF_a7q5hFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming df_new is your new dataset with a 'text' column\n",
        "df_new = pd.DataFrame({\n",
        "    'text': [\"This is a sample text\", \"Another example text\", \"More text samples\"]\n",
        "})\n",
        "\n",
        "# Tokenize the new text data\n",
        "new_encodings = tokenizer(df_new['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Create a DataLoader for the new data\n",
        "new_dataset = CustomDataset(new_encodings, pd.Series([0]*len(df_new)))  # Dummy labels\n",
        "new_dataloader = DataLoader(new_dataset, batch_size=4)\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "model.eval()\n",
        "all_preds = []\n",
        "for batch in new_dataloader:\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(model.device) for k, v in batch.items() if k != 'labels'})\n",
        "        all_preds.append(outputs.logits.cpu().numpy())\n",
        "\n",
        "# Convert output scores to predicted labels\n",
        "import numpy as np\n",
        "preds = np.concatenate(all_preds, axis=0)\n",
        "pred_labels = preds.argmax(axis=-1)\n",
        "\n",
        "# Map numeric labels back to original string labels\n",
        "predicted_labels = label_encoder.inverse_transform(pred_labels)\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stXsHAYl3JCx",
        "outputId": "141f1027-66e4-4002-9761-8f0f89f6dabb"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 3. 3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-117-a865eedcadf2>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ]
    }
  ]
}